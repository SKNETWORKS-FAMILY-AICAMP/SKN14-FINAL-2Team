from ..config import llm
from langchain_core.messages import HumanMessage, AIMessage
from ..state import AgentState
from ..prompts.faq_prompt import faq_prompt

def FAQ_agent_node(state: AgentState) -> AgentState:
    """FAQ agent - LLM ê¸°ë³¸ ì§€ì‹ìœ¼ë¡œ í–¥ìˆ˜ ê´€ë ¨ ì§ˆë¬¸ ë‹µë³€"""
    # ì•ˆì „í•˜ê²Œ ìµœì‹  ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ì¶œ
    user_query = "(empty)"
    for m in reversed(state.get("messages", [])):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break

    try:
        print(f"ğŸ” FAQ_agent ì‹¤í–‰: {user_query}")
        chain = faq_prompt | llm
        ai = chain.invoke({"question": user_query})
        body = getattr(ai, "content", str(ai))

        final_answer = f"ğŸ’¬ ë‹µë³€ ê²°ê³¼:\n{body}"

        # âœ… add_messages ì‚¬ìš© ì‹œ, ì´ë²ˆ í„´ì— â€œì¶”ê°€ë â€ ë©”ì‹œì§€ë§Œ ë°˜í™˜
        return {
            "messages": [AIMessage(content=final_answer)],
            "final_answer": final_answer,
            # router_jsonì€ ë°”ë€ ê²Œ ì—†ìœ¼ë©´ êµ³ì´ ë‹¤ì‹œ ë„£ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
        }
    except Exception as e:
        error_msg = f"âŒ í–¥ìˆ˜ ì§€ì‹ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        return {
            "messages": [AIMessage(content=error_msg)],
            "final_answer": error_msg,
        }
