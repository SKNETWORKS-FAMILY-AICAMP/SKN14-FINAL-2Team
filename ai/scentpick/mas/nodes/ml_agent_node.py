# scentpick/mas/nodes/ML_agent_node.py
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from ..state import AgentState
import json
from ..prompts.ML_agent_prompt import ML_agent_system_prompt
from ..tools.tools_recommend import recommend_perfume_vdb   # Pinecone VDB ê¸°ë°˜ ì¶”ì²œ ë„êµ¬
from ..tools.tools_parsers import run_llm_parser
from ..config import llm
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional

def _to_int_ml(v) -> Optional[int]:
    try:
        if v is None: return None
        if isinstance(v, (int, float)): return int(v)
        s = str(v).lower().replace("ml", "").strip()
        return int(float(s))
    except Exception:
        return None

def _normalize_item(raw: Dict[str, Any]) -> Optional[Dict[str, Any]]:
    """ë‹¤ì–‘í•œ í‚¤ ìŠ¤í‚¤ë§ˆë¥¼ í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ì •ê·œí™”"""
    if not isinstance(raw, dict):
        return None
    brand = (raw.get("brand") or raw.get("Brand") or raw.get("maker") or "").strip()
    name  = (raw.get("name") or raw.get("Name") or raw.get("perfume") or raw.get("title") or "").strip()
    if not name:
        return None
    size  = _to_int_ml(raw.get("size") or raw.get("size_ml") or raw.get("ml") or raw.get("Size"))
    url   = raw.get("detail_url") or raw.get("url") or raw.get("link") or raw.get("detailUrl")
    
    pid = raw.get("no") or raw.get("perfume_id") \
          or (raw.get("perfume_data") or {}).get("no")
    try:
        pid_int = int(float(pid)) if pid is not None else None
    except Exception:
        pid_int = None

    rank = raw.get("rank")
    score = raw.get("score") or 0.0
    perfume_data = raw.get("perfume_data") or {}
    text = perfume_data.get("text") if "text" in perfume_data else raw.get("text") or ""
    
    return {
        "id": pid_int,
        "brand": brand,
        "name": name,
        "size": size,
        "detail_url": url,
        "rank": rank,
        "score": score,
        "text": text,
        }

def _extract_candidates_from_ml_result(ml_result: Any, top_n: int = 3) -> List[Dict[str, Any]]:
    """
    ml_resultì˜ ê°€ëŠ¥í•œ êµ¬ì¡°ë¥¼ í­ë„“ê²Œ ì§€ì›:
    - {"items":[...]}, {"top_items":[...]}, {"recommendations":[...]}, {"recs":[...]}, {"candidates":[...]}
    """
    if not isinstance(ml_result, dict):
        return []
    # í›„ë³´ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
    for key in ("items", "top_items", "recommendations", "recs", "candidates"):
        arr = ml_result.get(key)
        if isinstance(arr, list) and arr:
            normed = []
            for it in arr:
                n = _normalize_item(it)
                if n:
                    normed.append(n)
            if normed:
                return normed[:top_n]
    return []

def _extract_brand_from_query(query: str) -> Optional[str]:
    known_brands = ["ìƒ¤ë„¬", "ë””ì˜¬", "êµ¬ì°Œ", "í†°í¬ë“œ", "ì¡°ë§ë¡ ", "ì…ìƒë¡œë‘"]
    for b in known_brands:
        if b.lower() in query.lower():
            return b
    return None

def ML_agent_node(state: AgentState) -> AgentState:
    """ML agent - Pinecone VDBë¥¼ í†µí•´ ìƒìœ„ Nê°œ ì¶”ì²œ í›„, LLMì´ ì„¤ëª…ë¬¸ ìƒì„± (ë©€í‹°í„´/rec_history ëˆ„ì )"""
    # 0) ìµœì‹  ì‚¬ìš©ì ë©”ì‹œì§€
    user_query = "(empty)"
    for m in reversed(state.get("messages", [])):
        if isinstance(m, HumanMessage):
            user_query = m.content
            break

    try:
        print(f"ğŸ” ML_parser ì‹¤í–‰: {user_query}")

        parsed_json = run_llm_parser(user_query)
        brand = parsed_json.get("brand")
        n_recs = int(parsed_json.get("recommendation_count") or 3)  # ê¸°ë³¸ê°’ 3

        params = {
            "user_text": user_query,
            "topk_labels": 3,
            "top_n_perfumes": n_recs,
            "use_thresholds": True,
            "alpha_labels": 0.8,
            "index_name": "perfume-vectordb2",
        }

        if brand:
            params["metadata_filter"] = {"brand": brand}

        # 1) VDB ê¸°ë°˜ ì¶”ì²œ
        ml_result = recommend_perfume_vdb.invoke(params)

        # 2) í›„ë³´ í‘œì¤€í™” (rec_echoê°€ ë°”ë¡œ ì½ì„ ìˆ˜ ìˆê²Œ)
        candidates = _extract_candidates_from_ml_result(ml_result, top_n=n_recs)

        # 3) LLM ì„¤ëª… ìƒì„± (ì‹œìŠ¤í…œ+íœ´ë¨¼ ë©”ì‹œì§€)
        ml_json_str = json.dumps(ml_result, ensure_ascii=False)
        human_prompt = (
            f"ì‚¬ìš©ì ì§ˆë¬¸:\n{user_query}\n\n"
            f"ML ì¶”ì²œ JSON:\n```json\n{ml_json_str}\n```"
        )
        llm_out = llm.invoke([
            SystemMessage(content=ML_agent_system_prompt),
            HumanMessage(content=human_prompt)
        ])
        explanation = getattr(llm_out, "content", "").strip()

        # 4) ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìµœì¢… í…ìŠ¤íŠ¸ (ë²ˆí˜¸ ë§¤ê²¨ì§„ ëª©ë¡ + ì„¤ëª…)
        if candidates:
            lines = []
            for i, r in enumerate(candidates, 1):
                line = f"{i}. {r.get('brand','')} {r.get('name','')}"
                if r.get("size"):
                    line += f" {r['size']}ml"
                lines.append(line)
            header = "ğŸ’¬ ì¶”ì²œ ê²°ê³¼:\n\n" + "\n".join(lines)
            final_answer = header + ("\n\n" + explanation if explanation else "")
        else:
            final_answer = "ì¶”ì²œ ê²°ê³¼ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”." + ("\n\n" + explanation if explanation else "")

        # 5) rec_historyì— ëˆ„ì  (ëª¨ë“œ A: ë‹¤ìŒ í„´ 'ë°©ê¸ˆ ì¶”ì²œ?' íšŒìƒìš©)
        entry = {
            "ts": datetime.now(timezone.utc).isoformat(),
            "source": "ML_agent",
            "items": candidates,  # í‘œì¤€ ìŠ¤í‚¤ë§ˆ
        }

        # perfume_list: id, brand, nameë§Œ ì¶”ì¶œ
        perfume_list = []
        for r in candidates:
            if r.get("id") and r.get("name"):
                perfume_list.append({
                    "id": r.get("id"),
                    "brand": r.get("brand"),
                    "name": r.get("name"),
                    "rank": r.get("rank"),
                    "score": r.get("score"),
                    "text": r.get("text"),
                })

        # 6) ë¸íƒ€ ë©”ì‹œì§€ë§Œ ë°˜í™˜
        return {
            "messages": [AIMessage(content=final_answer)],
            "final_answer": final_answer,
            "rec_history": [entry],        # ë¦¬ìŠ¤íŠ¸ ëˆ„ì 
            "last_agent": "ML_agent",      # supervisor í”„ë¡¬í”„íŠ¸ìš©
            "perfume_list": perfume_list,
        }

    except Exception as e:
        err = f"âŒ ML ì¶”ì²œ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        return {
            "messages": [AIMessage(content=err)],
            "final_answer": err,
            "last_agent": "ML_agent",
            "perfume_list": [],
        }
