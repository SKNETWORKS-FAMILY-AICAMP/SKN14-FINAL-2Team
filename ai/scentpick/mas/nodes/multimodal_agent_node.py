from langchain_core.messages import AIMessage, HumanMessage
from ..state import AgentState
from ..tools.tools_rag import query_pinecone, generate_response
from ..tools.tools_metafilters import apply_meta_filters
from ..config import llm, embeddings
from openai import OpenAI
from datetime import datetime, timezone
import json

client = OpenAI()

def multimodal_agent_node(state: AgentState) -> AgentState:
    img_url = state.get("image_url")
    if not img_url:
        return {"messages": [AIMessage(content="ì´ë¯¸ì§€ë¥¼ ì²¨ë¶€í•´ì£¼ì„¸ìš”.")], "next": None}

    # 1) ìµœì‹  user query (í…ìŠ¤íŠ¸)
    query = ""

    if not query and img_url:
        query = "ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ì²œ ìš”ì²­"

    for m in reversed(state.get("messages", [])):
        if isinstance(m, HumanMessage):
            query = m.content or ""
            break

    # 2) GPT-4o-minië¡œ ì´ë¯¸ì§€ ë¶„ì„ (JSON í˜•ì‹ ê°•ì œ)
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": """
            Analyze the uploaded perfume-related image. 
            Output STRICT JSON with the following keys if detectable:
            - day_night_score (day or night)
            - gender (Male, Female, Unisex)
            - season_score (spring, summer, fall, winter)
            - free_text (short natural language summary: mood, color impression, style, etc.)
            """},
            {"role": "user", "content": [
                {"type": "text", "text": query or "ì´ ì´ë¯¸ì§€ì—ì„œ í–¥ìˆ˜ ì¶”ì²œì— ë„ì›€ì´ ë˜ëŠ” ë‹¨ì„œë¥¼ ì¶”ì¶œí•´ì¤˜."},
                {"type": "image_url", "image_url": {"url": img_url}}
            ]}
        ],
        max_tokens=400,
    )

    raw_analysis = response.choices[0].message.content

    try:
        analysis_json = json.loads(raw_analysis)
    except Exception:
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ free_textì— ì „ì²´ ë©”ì‹œì§€ ë„£ê¸°
        analysis_json = {"free_text": raw_analysis}

    # 3) ë©”íƒ€í•„í„° ì ìš©
    filtered_json = apply_meta_filters(analysis_json)

    print(f"ğŸ” multimodal_agent_node ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼: {json.dumps(analysis_json, ensure_ascii=False)}")

    # 4) Pinecone ê²€ìƒ‰ (free_textëŠ” ë²¡í„° ê²€ìƒ‰, ë‚˜ë¨¸ì§€ëŠ” ë©”íƒ€í•„í„°)
    query_text = analysis_json.get("free_text", query)
    query_vector = embeddings.embed_query(query_text)
    search_results = query_pinecone(query_vector, filtered_json, top_k=3)
    if hasattr(search_results, "to_dict"):
        search_results = search_results.to_dict()

    # 5) LLMìœ¼ë¡œ ìµœì¢… ì¶”ì²œ ë‹µë³€ ìƒì„±
    final_response = generate_response(
        original_query=f"{query} + ì´ë¯¸ì§€ ë¶„ì„: {json.dumps(analysis_json, ensure_ascii=False)}",
        search_results=search_results,
        limit=3
    )

    # 6) perfume_list ì •ê·œí™”
    perfume_list = []
    for match in search_results.get("matches", []):
        meta = match.get("metadata", {}) or {}
        pid = meta.get("no")   # âœ… DBìš© ì •ìˆ˜ id
        try:
            pid = int(pid) if pid is not None else None
        except Exception:
            pid = None

        if pid:
            perfume_list.append({
                "id": pid,
                "brand": meta.get("brand"),
                "name": meta.get("name"),
                "score": match.get("score"),
                "text": meta.get("text"),
            })

    # 7) history entry (rec_echo ìš©)
    entry = {
        "ts": datetime.now(timezone.utc).isoformat(),
        "source": "multimodal_agent",
        "items": search_results.get("matches", []),
    }

    return {
        "messages": [AIMessage(content=final_response)],
        "search_results": search_results,
        "final_answer": final_response,
        "rec_history": [entry],
        "last_agent": "multimodal_agent",
        "perfume_list": perfume_list,
    }